{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===========================================\n",
    "\n",
    "\n",
    "Title: 5.2 Exercises\n",
    "\n",
    "\n",
    "Author: Chad Wood\n",
    "\n",
    "\n",
    "Date: 23 Jan 2022\n",
    "\n",
    "\n",
    "Modified By: Chad Wood\n",
    "\n",
    "\n",
    "Description: This program demonstrates building a directory structure for a small retail business' data lake.\n",
    "\n",
    "=========================================== "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquiring and Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Assignment 5\n",
    "\n",
    "For this assignment and future assignments, assume that you are the owner of a small but growing retail business, *Datums R Us*. Your store sells technology, tools, and clothing for the discerning data scientist. You currently have stores in the following five locations. \n",
    "\n",
    "- Bellevue, Nebraska\n",
    "- Columbus, Ohio\n",
    "- Denver, Colorado\n",
    "- San Francisco, California\n",
    "- Baltimore, Maryland\n",
    "\n",
    "You have been tasked with creating a data lake for the company using a [directory structure based on Cookiecutter Data Science recommendations](https://drivendata.github.io/cookiecutter-data-science/#directory-structure). This basic directory structure works well for small, self-contained data science projects and organizing large-scale data warehouses.\n",
    "\n",
    "```\n",
    "├── data\n",
    "│   ├── external       <- Data from third-party sources.\n",
    "│   ├── interim        <- Intermediate data that has been transformed.\n",
    "│   ├── processed      <- The final, canonical data sets for modeling and reports.\n",
    "│   └── raw            <- The original, immutable data dump.\n",
    "```\n",
    "\n",
    "You have identified the following items for initial inclusion in the data lake. \n",
    "\n",
    "**External Data Sets**\n",
    "\n",
    "- Census (Updated Yearly)\n",
    "- Weather Forecasts (Updated Daily)\n",
    "\n",
    "**Raw Data Dumps**\n",
    "\n",
    "- Sales (Updated Hourly)\n",
    "- Inventory (Updated Daily)\n",
    "- Expenses (Updated Daily)\n",
    "\n",
    "**Processed Data Sets and Reports**\n",
    "\n",
    "*Weekly*\n",
    "\n",
    "- Modeling Data Set\n",
    "\n",
    "*Monthly*\n",
    "\n",
    "- Inventory Update Request\n",
    "\n",
    "*Quarterly*\n",
    "\n",
    "- Quarterly Financial Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5.1\n",
    "\n",
    "In the first part of the assignment, you will describe the directory structure for the data lake. For the most part, this directory structure will not depend on the technical details of how you store the data. You could be storing the data in a local filesystem, a distributed filesystem such as HDFS, or object storage, such as Amazon S3. \n",
    "\n",
    "You will only be creating the directory structures and not populating actual content. Real-world data lakes store data in a variety of formats including,  Apache Parquet, Google Protocol Buffers, Apache Avro, JSONL, and CSV. \n",
    "\n",
    "You will use Python's built-in [calendar library](https://docs.python.org/3/library/calendar.html), and [datetime library](https://docs.python.org/3/library/datetime.html) to work with the dates and times required for this assignment. You will use the [PurePosixPath](https://docs.python.org/3/library/pathlib.html#pathlib.PurePosixPath) class from Python's built-in [pathlib library](https://docs.python.org/3/library/pathlib.html) to represent locations on the data lake. \n",
    "\n",
    "You will generate the output directories for an entire year's worth of data starting on January 1st of this year. Unless otherwise specified, all times will be in Coordinated Universal Time (UTC). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the required Python libraries and \n",
    "# sets global variables for the assignment\n",
    "import calendar\n",
    "import datetime\n",
    "from pathlib import PurePosixPath\n",
    "\n",
    "today = datetime.date.today()\n",
    "current_year = today.year\n",
    "days_in_year = 365\n",
    "\n",
    "if calendar.isleap(current_year):\n",
    "    days_in_year +=1\n",
    "\n",
    "hours_in_year = days_in_year * 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Data Directory: /data\n",
      "External Data Directory: /data/external\n",
      "Interim Data Directory: /data/interim\n",
      "Processed Data Directory: /data/processed\n",
      "Raw Data Directory: /data/raw\n"
     ]
    }
   ],
   "source": [
    "# Creates paths for the external, interim, processed, and raw directories\n",
    "# Use these paths when creating new paths\n",
    "\n",
    "root_data_dir = PurePosixPath('/data')\n",
    "external_data_dir = root_data_dir.joinpath('external')\n",
    "interim_data_dir = root_data_dir.joinpath('interim')\n",
    "processed_data_dir = root_data_dir.joinpath('processed')\n",
    "raw_data_dir = root_data_dir.joinpath('raw')\n",
    "\n",
    "print('Root Data Directory: {}'.format(root_data_dir))\n",
    "print('External Data Directory: {}'.format(external_data_dir))\n",
    "print('Interim Data Directory: {}'.format(interim_data_dir))\n",
    "print('Processed Data Directory: {}'.format(processed_data_dir))\n",
    "print('Raw Data Directory: {}'.format(raw_data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.1.a/b/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For the purposes of this assignment, we will be using three Census data sets as examples of external data updated yearly. These data sets are:\n",
    "\n",
    "- [American Community Survey (ACS) Summary File](https://www.census.gov/programs-surveys/acs/data/summary-file.html)\n",
    "- [American Community Survey (ACS) Public Use Microdata Sample (PUMS)]( https://www.census.gov/programs-surveys/acs/microdata.html)\n",
    "- [Tiger/Line Shapefiles](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html)\n",
    "\n",
    "If you are curious, you can find the actual data sets at the following locations: \n",
    "\n",
    "- [ACS Summary File](https://www2.census.gov/programs-surveys/acs/summary_file/)\n",
    "- [PUMS](https://www2.census.gov/programs-surveys/acs/data/pums/)\n",
    "- [Tiger](https://www2.census.gov/geo/tiger/)\n",
    "\n",
    "For this assignment, we use the following naming convention for external data sets\n",
    "\n",
    "```\n",
    "/data/external/<source>/<data-set>/<year>/\n",
    "```\n",
    "where *source* is the organization providing the data, *data-set* is the specific data set, and *year* is the year. \n",
    "\n",
    "```\n",
    "data\n",
    "├── external\n",
    "│   ├── census\n",
    "│   │   ├── acs-summaryfile\n",
    "│   │   │   ├── 2015\n",
    "│   │   │   ├── 2016\n",
    "│   │   │   ...\n",
    "│   │   │   ...\n",
    "│   │   │   └── 2019\n",
    "│   │   ├── pums\n",
    "│   │   │   ├── 2015\n",
    "│   │   │   ├── 2016\n",
    "│   │   │   ...\n",
    "│   │   │   ...\n",
    "│   │   │   └── 2020\n",
    "│   │   └── tiger\n",
    "│   │       ├── 2015\n",
    "│   │       ├── 2016\n",
    "│   │   │   ...\n",
    "│   │   │   ...\n",
    "│   │       └── 2020\n",
    "│   └── nwc-wpc\n",
    "├── interim\n",
    "├── processed\n",
    "└── raw\n",
    "```\n",
    "\n",
    "Create and add the paths for these data sets. Verify that you have added the paths correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_summary_file_dirs = set()\n",
    "pums_dirs = set()\n",
    "tiger_dirs = set()\n",
    "\n",
    "# TODO: Create and add the paths for this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will generate directories to reduce repeated code\n",
    "# This function is continiously used throughout assignment\n",
    "def DirGenerator(root, dir_names, add_to=None):\n",
    "    paths = [root.joinpath(directory) for directory in dir_names]\n",
    "    # Appends to a set for refrence\n",
    "    if add_to is not None:\n",
    "        for path in paths:\n",
    "            add_to.add(format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/data/external/census/acs-summaryfile/2015',\n",
       "  '/data/external/census/acs-summaryfile/2016',\n",
       "  '/data/external/census/acs-summaryfile/2017',\n",
       "  '/data/external/census/acs-summaryfile/2018',\n",
       "  '/data/external/census/acs-summaryfile/2019'],\n",
       " ['/data/external/census/pums/2015',\n",
       "  '/data/external/census/pums/2016',\n",
       "  '/data/external/census/pums/2017',\n",
       "  '/data/external/census/pums/2018',\n",
       "  '/data/external/census/pums/2019',\n",
       "  '/data/external/census/pums/2020'],\n",
       " ['/data/external/census/tiger/2015',\n",
       "  '/data/external/census/tiger/2016',\n",
       "  '/data/external/census/tiger/2017',\n",
       "  '/data/external/census/tiger/2018',\n",
       "  '/data/external/census/tiger/2019',\n",
       "  '/data/external/census/tiger/2020'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates initial directories\n",
    "census_data_dir = external_data_dir.joinpath('census')\n",
    "acs_summary_data_dir = census_data_dir.joinpath('acs-summaryfile')\n",
    "pums_data_dir = census_data_dir.joinpath('pums')\n",
    "tiger_data_dir = census_data_dir.joinpath('tiger')\n",
    "\n",
    "# Generates the directories\n",
    "years = ['2015', '2016', '2017', '2018', '2019']       \n",
    "DirGenerator(acs_summary_data_dir, years, add_to=acs_summary_file_dirs)\n",
    "\n",
    "years = ['2015', '2016', '2017', '2018', '2019', '2020']\n",
    "DirGenerator(pums_data_dir, years, add_to=pums_dirs)\n",
    "DirGenerator(tiger_data_dir, years, add_to=tiger_dirs)\n",
    "\n",
    "# Should output sorted directories from 2015 to present \n",
    "sorted(list(acs_summary_file_dirs)), sorted(list(pums_dirs)), sorted(list(tiger_dirs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.1.d\n",
    "\n",
    "Finally, you will create directories for a daily data set based on the [National Weather Service's (NWS) Weather Prediction Center's (WPC) daily forecasts](https://www.wpc.ncep.noaa.gov/kml/kmlproducts.php). \n",
    "\n",
    "For this part, we use the following naming convention\n",
    "\n",
    "```\n",
    "/data/external/nwc-wpc/forecasts/<year>/<month>/<day>/\n",
    "```\n",
    "where *year* is the year, *month* is the two-digit month, and *day* is the two-digit day. We use this convention when working with date-based data as the directories are naturally in date order. \n",
    "\n",
    "```\n",
    "data\n",
    "├── external\n",
    "│   ├── census\n",
    "│   └── nwc-wpc\n",
    "│       └── forecasts\n",
    "│           └── 2020\n",
    "│               ├── 01\n",
    "│               │   ├── 01\n",
    "│               │   ├── 02\n",
    "│               │   ├── 03\n",
    "│               │   ...\n",
    "│               │   ...\n",
    "│               │   ├── 30\n",
    "│               │   └── 31\n",
    "│               ├── 02\n",
    "│               │   ├── 01\n",
    "│               │   ├── 02\n",
    "│               │   ...\n",
    "│               │   ...\n",
    "│               │   ├── 28\n",
    "│               │   └── 29\n",
    "│               ├── 03\n",
    "│               ...\n",
    "│               ...\n",
    "│               ├── 11\n",
    "│               └── 12\n",
    "│                   ├── 01\n",
    "│                   ├── 02\n",
    "│                   ...\n",
    "│                   ...\n",
    "│                   ├── 29\n",
    "│                   ├── 30\n",
    "│                   └── 31\n",
    "├── interim\n",
    "├── processed\n",
    "└── raw\n",
    "```\n",
    "\n",
    "Create and add the paths for these data sets. Verify that you have added the paths correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code below is used to build dict structure {month: [days]}\n",
    "# Helpful for passing to function DirGenerator\n",
    "import calendar\n",
    "\n",
    "# Collapses dates in calander dates list\n",
    "def flatten(dates):\n",
    "    for i in dates:\n",
    "        if isinstance(i, list):\n",
    "            for j in flatten(i):\n",
    "                yield j\n",
    "        else:\n",
    "            yield i\n",
    "            \n",
    "\n",
    "cal = calendar.Calendar()\n",
    "year = 2020\n",
    "\n",
    "# Creates dict with {month: []} pairs\n",
    "dates = list(flatten(cal.yeardatescalendar(year)))\n",
    "months = set(str(date.month) for date in dates)\n",
    "month_days = {month: [] for month in months}\n",
    "\n",
    "# Adds list of values for each month's days within month_days\n",
    "for date in dates:\n",
    "    if str(date.day) not in month_days[str(date.month)]:\n",
    "        month_days[str(date.month)].append(str(date.day))\n",
    "\n",
    "# Creates padding with 0s (e.g., 1 to 01)\n",
    "padded_dict = {}\n",
    "for month, days in month_days.items():\n",
    "    days = [str(day.zfill(2)) for day in days]\n",
    "    padded_dict[str(month.zfill(2))] = list(days)\n",
    "    \n",
    "month_days = padded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_dirs = set()\n",
    "\n",
    "# TODO: Create and add the paths for this data set\n",
    "\n",
    "# Creates initial directories\n",
    "nwc_wpc_data_dir = external_data_dir.joinpath('nwc-wpc')\n",
    "forecasts_data_dir = nwc_wpc_data_dir.joinpath('forecasts')\n",
    "for2020_data_dir = forecasts_data_dir.joinpath('2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates directories for months\n",
    "DirGenerator(for2020_data_dir, months)\n",
    "\n",
    "# Creates directories for days in months dirs\n",
    "parent = format(for2020_data_dir)\n",
    "for month, days in month_days.items():\n",
    "    child = PurePosixPath((f'{parent}/{month}'))\n",
    "    DirGenerator(child, days, add_to=forecast_dirs)\n",
    "\n",
    "# Should have 365 directories (366 if leap year)\n",
    "len(forecast_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5.2\n",
    "\n",
    "In the second part of the assignment, you will create the structure for the raw source data. We will use the following directory naming convention. \n",
    "\n",
    "```\n",
    "/data/raw/inventory/<location>/<year>/<month>/<day>/\n",
    "/data/raw/expenses/<location>/<year>/<month>/<day>/\n",
    "/data/raw/sales/<location>/<year>/<month>/<day>/<hour>/\n",
    "```\n",
    "For *location*, we will use the three-letter IATA code for the airport nearest to the location.  We will use the same year, month, and day convention from the previous example. For *hour*, we will use the two-digit hour value based on a 24-hour clock set to UTC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.2.a\n",
    "\n",
    "The following is an example of the directory structure for daily data dumps. \n",
    "\n",
    "```\n",
    "data\n",
    "├── external\n",
    "├── interim\n",
    "├── processed\n",
    "└── raw\n",
    "    ├── expenses\n",
    "    ├── inventory\n",
    "    │   ├── bwi\n",
    "    │   ├── cmh\n",
    "    │   ├── den\n",
    "    │   ├── oma\n",
    "    │   │   └── 2020\n",
    "    │   │       ├── 01\n",
    "    │   │       │   ├── 01\n",
    "    │   │       │   ├── 02\n",
    "    │   │       │   ...    \n",
    "    │   │       │   └── 31\n",
    "    │   │       ├── 02\n",
    "    │   │       │   ├── 01\n",
    "    │   │       │   ...\n",
    "    │   │       │   └── 29\n",
    "    │   │       ├── 03\n",
    "    │   │       ... \n",
    "    │   │       ├── 11\n",
    "    │   │       └── 12\n",
    "    │   │           ├── 01\n",
    "    │   │           ├── 02\n",
    "    │   │           ...  \n",
    "    │   │           └── 31\n",
    "    │   └── sfo\n",
    "    └── sales\n",
    "```\n",
    "\n",
    "Create and add the paths for these data sets. Verify that you have added the paths correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_dirs = set()\n",
    "expenses_dirs = set()\n",
    "\n",
    "# TODO: Create and add the paths for this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates initial directories\n",
    "raw_expenses_data_dir = raw_data_dir.joinpath('expenses')\n",
    "raw_inventory_data_dir = raw_data_dir.joinpath('inventory')\n",
    "\n",
    "in_location_dirs = [raw_inventory_data_dir.joinpath('bwi'),\n",
    "                    raw_inventory_data_dir.joinpath('cmh'),\n",
    "                    raw_inventory_data_dir.joinpath('den'),\n",
    "                    raw_inventory_data_dir.joinpath('oma'),\n",
    "                    raw_inventory_data_dir.joinpath('sfo')]\n",
    "\n",
    "ex_location_dirs = [raw_expenses_data_dir.joinpath('bwi'),\n",
    "                    raw_expenses_data_dir.joinpath('cmh'),\n",
    "                    raw_expenses_data_dir.joinpath('den'),\n",
    "                    raw_expenses_data_dir.joinpath('oma'),\n",
    "                    raw_expenses_data_dir.joinpath('sfo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates directories for months in inventory location dirs\n",
    "for location_dir in in_location_dirs:\n",
    "    DirGenerator(location_dir, months)\n",
    "\n",
    "# Creates directories for months in expenses location dirs\n",
    "for location_dir in ex_location_dirs:\n",
    "    DirGenerator(location_dir, months)\n",
    "\n",
    "# Creates directories for days in inventory\n",
    "for PosixPath in in_location_dirs:\n",
    "    # Formats parent path\n",
    "    parent = f'{format(PosixPath)}/2020'\n",
    "    for month, days in month_days.items():\n",
    "        child = PurePosixPath((f'{parent}/{month}'))\n",
    "        DirGenerator(child, days, add_to=inventory_dirs)\n",
    "\n",
    "# Creates directories for days in expenses\n",
    "for PosixPath in ex_location_dirs:\n",
    "    # Formats parent path\n",
    "    parent = f'{format(PosixPath)}/2020'\n",
    "    for month, days in month_days.items():\n",
    "        child = PurePosixPath((f'{parent}/{month}'))\n",
    "        DirGenerator(child, days, add_to=expenses_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1830, 1830)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should have 1825 directories (1830 if leap year)\n",
    "len(inventory_dirs), len(expenses_dirs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.2.b\n",
    "\n",
    "Finally, create the paths for the hourly sales data. The following is an example of the directory structure for the sales data. \n",
    "\n",
    "```\n",
    "├── external\n",
    "├── interim\n",
    "├── processed\n",
    "└── raw\n",
    "    ├── expenses\n",
    "    ├── inventory\n",
    "    └── sales\n",
    "        ├── bwi\n",
    "        ├── cmh\n",
    "        ├── den\n",
    "        ├── oma\n",
    "        │   └── 2020\n",
    "        │       ├── 01\n",
    "        │       │   └── 01\n",
    "        │       │       ├── 00\n",
    "        │       │       ├── 01   \n",
    "        │       │       ├── 02\n",
    "        │       │       ...     \n",
    "        │       │       ├── 22\n",
    "        │       │       └── 23\n",
    "        │       ├── 02\n",
    "        │       ...\n",
    "        │       └── 12\n",
    "        └── sfo\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_dirs = set()\n",
    "\n",
    "# TODO: Create and add the paths for this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates initial directories\n",
    "raw_sales_data_dir = raw_data_dir.joinpath('sales')\n",
    "\n",
    "sales_location_dirs = [raw_sales_data_dir.joinpath('bwi'),\n",
    "                       raw_sales_data_dir.joinpath('cmh'),\n",
    "                       raw_sales_data_dir.joinpath('den'),\n",
    "                       raw_sales_data_dir.joinpath('oma'),\n",
    "                       raw_sales_data_dir.joinpath('sfo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates directories for months in sales location dirs\n",
    "for location_dir in sales_location_dirs:\n",
    "    DirGenerator(location_dir, months)\n",
    "\n",
    "# Creates directories for days in sales\n",
    "for PosixPath in sales_location_dirs:\n",
    "    # Formats parent path\n",
    "    parent = f'{format(PosixPath)}/2020'\n",
    "    for month, days in month_days.items():\n",
    "        child = PurePosixPath((f'{parent}/{month}'))\n",
    "        DirGenerator(child, days, add_to=sales_dirs)\n",
    "\n",
    "# Lists hours in a day\n",
    "hours = [str(hour).zfill(2) for hour in range(24)]\n",
    "\n",
    "# Creates directories for hours in sales\n",
    "hourly_sales_dirs = set()\n",
    "for sales_day_dir in sales_dirs:\n",
    "    parent = PurePosixPath(sales_day_dir)\n",
    "    DirGenerator(parent, hours, add_to=hourly_sales_dirs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43920"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_dirs = hourly_sales_dirs\n",
    "\n",
    "# Should have 43,800 directories (43,920 if leap year)\n",
    "len(sales_dirs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.3.a\n",
    "\n",
    "We have two choices for structuring our weekly data set. We can use the following naming convention where the date is based on the first day of the week. \n",
    "\n",
    "```\n",
    "/data/processed/modeling/<year>/<month>/<day>/\n",
    "```\n",
    "\n",
    "Otherwise, we could use a naming convention where *week* is the number of weeks it has been since the beginning of the year. \n",
    " \n",
    "```\n",
    "/data/processed/modeling/<year>/<week>/\n",
    "```\n",
    "\n",
    "We will use the first option for our naming convention. Python's *calendar* library has a function that determines the first day of the week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data_dirs = set()\n",
    "\n",
    "# TODO: Create and add the paths for this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "week_starter = 0\n",
    "\n",
    "# Creates dict {month: [week_start_date]} for year\n",
    "month_weeks = {str(month+1): [] for month in range(12)}\n",
    "for i in range(12):\n",
    "    month = i+1\n",
    "    for date in cal.itermonthdays4(year, month):\n",
    "        if date[0] == year and date[3] == week_starter:\n",
    "            if str(date[2]) not in month_weeks[str(date[1])]:\n",
    "                month_weeks[str(date[1])].append(str(date[2]))\n",
    "            \n",
    "# Creates padding with 0s (e.g., 1 to 01)\n",
    "padded_dict = {}\n",
    "for month, weeks in month_weeks.items():\n",
    "    weeks = [str(week.zfill(2)) for week in weeks]\n",
    "    padded_dict[str(month.zfill(2))] = list(weeks)\n",
    "    \n",
    "month_weeks = padded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates initial directory\n",
    "modeling_data_dir = processed_data_dir.joinpath('modeling')\n",
    "\n",
    "# Creates directories for months\n",
    "DirGenerator(modeling_data_dir, months)\n",
    "\n",
    "# Creates directories for days in months dirs\n",
    "parent = format(modeling_data_dir)\n",
    "for month, weeks in month_weeks.items():\n",
    "    child = PurePosixPath((f'{parent}/{month}'))\n",
    "    DirGenerator(child, weeks, add_to=modeling_data_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should have 52 directories\n",
    "len(modeling_data_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.3.b\n",
    "\n",
    "Next, create the monthly inventory requests using the following convention. \n",
    "\n",
    "```\n",
    "/data/processed/inventory/requests/<year>/<month>/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_request_dirs = set()\n",
    "\n",
    "# TODO: Create and add the paths for this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates initial directory\n",
    "inventory_data_dir = processed_data_dir.joinpath('inventory')\n",
    "requests_data_dir = processed_data_dir.joinpath('requests')\n",
    "requests2020_data_dir = processed_data_dir.joinpath('2020')\n",
    "\n",
    "# Generates the month directories\n",
    "DirGenerator(requests2020_data_dir, month_days.keys(), add_to=inventory_request_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/processed/2020/01',\n",
       " '/data/processed/2020/02',\n",
       " '/data/processed/2020/03',\n",
       " '/data/processed/2020/04',\n",
       " '/data/processed/2020/05',\n",
       " '/data/processed/2020/06',\n",
       " '/data/processed/2020/07',\n",
       " '/data/processed/2020/08',\n",
       " '/data/processed/2020/09',\n",
       " '/data/processed/2020/10',\n",
       " '/data/processed/2020/11',\n",
       " '/data/processed/2020/12']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Should output 12 directories\n",
    "sorted(list(inventory_request_dirs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.3.c\n",
    "\n",
    "Finally, create the quarterly financial reports using the following convention. \n",
    "\n",
    "```\n",
    "`/data/processed/financials/quarterly/<year>/<quarter>/`\n",
    "```\n",
    "While it does not matter for this assignment, the following are the typical dates associated with financial quarters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials_dirs = set()\n",
    "\n",
    "# TODO: Create and add the paths for this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates initial directory\n",
    "financials_data_dir = processed_data_dir.joinpath('financials')\n",
    "quarterly_data_dir = financials_data_dir.joinpath('quarterly')\n",
    "quarterly2020_data_dir = quarterly_data_dir.joinpath('2020')\n",
    "\n",
    "quarters = ['01', '02', '03', '04']\n",
    "\n",
    "# Generates the quarterly directories\n",
    "DirGenerator(quarterly2020_data_dir, quarters, add_to=financials_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/processed/financials/quarterly/2020/01',\n",
       " '/data/processed/financials/quarterly/2020/02',\n",
       " '/data/processed/financials/quarterly/2020/03',\n",
       " '/data/processed/financials/quarterly/2020/04']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should output four quarterly directories\n",
    "sorted(list(financials_dirs)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
